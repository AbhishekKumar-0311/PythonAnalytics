{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "# Introduction\n",
    "This exercise uses a small subset of the data from Kaggle's Yelp Business Rating Prediction competition.\n",
    "Description of the data:\n",
    "1. yelp.csv contains the dataset. It is stored in the repository (in the data directory), so there is no need to download anything from the Kaggle website.\n",
    "2. Each observation (row) in this dataset is a review of a particular business by a particular user.\n",
    "3. The stars column is the number of stars (1 through 5) assigned by the reviewer to the business. (Higher stars is better.) In other words, it is the rating of the business by the person who wrote the review.\n",
    "4. The text column is the text of the review.\n",
    "4. **Goal:** Predict the star rating of a review using only the review text.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "Read yelp.csv into a pandas DataFrame and examine it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the entire file of json\n",
    "with open('..\\..\\HeavyDataset\\Yelp Business Rating Prediction\\yelp_training_set\\yelp_training_set_review.json', 'rb') as file:\n",
    "    data = file.readlines()\n",
    "\n",
    "# Joining all data into a lump JSON String\n",
    "data_json_str = \"[\" + ','.join(data) + \"]\"\n",
    "\n",
    "# now, load it into pandas\n",
    "df = pd.read_json(data_json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>{u'funny': 0, u'useful': 5, u'cool': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>review</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>{u'funny': 0, u'useful': 0, u'cool': 0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6oRAC4uyJCsJl1X0WZpVSA</td>\n",
       "      <td>2012-06-14</td>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>review</td>\n",
       "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
       "      <td>{u'funny': 0, u'useful': 1, u'cool': 0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_1QQZuf4zZOyFCvXc0o6Vg</td>\n",
       "      <td>2010-05-27</td>\n",
       "      <td>G-WvGaISbqqaMHlNnByodA</td>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>uZetl9T0NcROGOyFfughhg</td>\n",
       "      <td>{u'funny': 0, u'useful': 2, u'cool': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6ozycU1RpktNG2-1BroVtw</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>1uJFq2r5QfJG_6ExMRCaGw</td>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>vYmM4KTsC8ZfQBg-j5MWkw</td>\n",
       "      <td>{u'funny': 0, u'useful': 0, u'cool': 0}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id       date               review_id  stars  \\\n",
       "0  9yKzy9PApeiPPOUJEtnvkg 2011-01-26  fWKvX83p0-ka4JS3dc6E5A      5   \n",
       "1  ZRJwVLyzEJq1VAihDhYiow 2011-07-27  IjZ33sJrzXqU-0X6U8NwyA      5   \n",
       "2  6oRAC4uyJCsJl1X0WZpVSA 2012-06-14  IESLBzqUCLdSzSqm0eCSxQ      4   \n",
       "3  _1QQZuf4zZOyFCvXc0o6Vg 2010-05-27  G-WvGaISbqqaMHlNnByodA      5   \n",
       "4  6ozycU1RpktNG2-1BroVtw 2012-01-05  1uJFq2r5QfJG_6ExMRCaGw      5   \n",
       "\n",
       "                                                text    type  \\\n",
       "0  My wife took me here on my birthday for breakf...  review   \n",
       "1  I have no idea why some people give bad review...  review   \n",
       "2  love the gyro plate. Rice is so good and I als...  review   \n",
       "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...  review   \n",
       "4  General Manager Scott Petello is a good egg!!!...  review   \n",
       "\n",
       "                  user_id                                    votes  \n",
       "0  rLtl8ZkDX5vH5nAx9C3q5Q  {u'funny': 0, u'useful': 5, u'cool': 2}  \n",
       "1  0a2KyEL0d3Yb1V6aivbIuQ  {u'funny': 0, u'useful': 0, u'cool': 0}  \n",
       "2  0hT2KtfLiobPvh6cDC8JQg  {u'funny': 0, u'useful': 1, u'cool': 0}  \n",
       "3  uZetl9T0NcROGOyFfughhg  {u'funny': 0, u'useful': 2, u'cool': 1}  \n",
       "4  vYmM4KTsC8ZfQBg-j5MWkw  {u'funny': 0, u'useful': 0, u'cool': 0}  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "Create a new DataFrame that only contains the 5-star and 1-star reviews.\n",
    "Hint: How do I apply multiple filter criteria to a pandas DataFrame? explains how to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dftoplow = df[(df['stars']==1) | (df['stars']==5) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93709, 8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftoplow.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "Define X and y from the new DataFrame, and then split X and y into training and testing sets, using the review text as the only feature and the star rating as the response.\n",
    "Hint: Keep in mind that X should be a pandas Series (not a DataFrame), since we will pass it to CountVectorizer in the task that follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X =  dftoplow['text']\n",
    "y = dftoplow['stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70281L,)\n",
      "(70281L,)\n",
      "(23428L,)\n",
      "(23428L,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "Use CountVectorizer to create document-term matrices from X_train and X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.79 s\n"
     ]
    }
   ],
   "source": [
    "%time X_train_dtm = vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_dtm = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5\n",
    "Use multinomial Naive Bayes to predict the star rating for the reviews in the testing set, and then calculate the accuracy and print the confusion matrix.\n",
    "Hint: Evaluating a classification model explains how to interpret both classification accuracy and the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_dtm,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 5 5 ..., 1 5 5]\n"
     ]
    }
   ],
   "source": [
    "y_pred_class = nb.predict(X_test_dtm)\n",
    "print(y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.931534915486\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(y_test,y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3731   658]\n",
      " [  946 18093]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_test,y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6 (Challenge)\n",
    "Calculate the null accuracy, which is the classification accuracy that could be achieved by always predicting the most frequent class.\n",
    "Hint: Evaluating a classification model explains null accuracy and demonstrates two ways to calculate it, though only one of those ways will work in this case. Alternatively, you can come up with your own method to calculate null accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    19039\n",
      "1     4389\n",
      "Name: stars, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Examine the class distribution of testing set\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    0.81266\n",
       "Name: stars, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate null accuracy\n",
    "y_test.value_counts().head(1)/y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7 (Challenge)\n",
    "Browse through the review text of some of the false positives and false negatives. Based on your knowledge of how Naive Bayes works, do you have any ideas about why the model is incorrectly classifying these reviews?\n",
    "Hint: Evaluating a classification model explains the definitions of \"false positives\" and \"false negatives\".\n",
    "Hint: Think about what a false positive means in this context, and what a false negative means in this context. What has scikit-learn defined as the \"positive class\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180398    I have been eating Chicago Style Food for 25 y...\n",
       "22525     This is in my neighborhood and I heard good th...\n",
       "127083    What happened? I have no idea. With all the ac...\n",
       "52786     Please note, this is my very first review of a...\n",
       "30751     decided to hit me with two months of dues when...\n",
       "213544    Very disappointed.  Place feels and looks like...\n",
       "41783     i'm not in love with this chain, and this loca...\n",
       "26889     So I figured out why this place has 5 from one...\n",
       "201166    I went to this place because it was closed my ...\n",
       "45563     \"Arribas: At least you won't die.\"\\n\\nBland fo...\n",
       "6051      This place has really bad service and the food...\n",
       "29579     The staff was friendly. That's about the only ...\n",
       "100690    These people have NO idea what they are doing....\n",
       "152035    I have been coming here for a while now. I lik...\n",
       "192552    Cool historic building but the service at lunc...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# False positives\n",
    "X_test[y_test<y_pred_class].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u\"This is in my neighborhood and I heard good things so I decided to give it a shot. The place is not recommended dine in as it gives me the feeling of an indoor version of one of them mobile food wagons with some fold out benches setup. We ordered some carne asada tacos and some guacamole and chips and a few bottled cokes I believe. \\n\\n\\n The carne asada tacos portion of meat inside was small and the portions of guacamole,cabbage, and onions outweighed the 10 miniscule pieces of meat inside. The taco had almost a hint of peanut butter taste to the guacamole inside the tacos and dip which is disgusting. I am not sure if it was the crazy amount of cabbage that caused the taste but pretty gross. I am completely stunned how anyone can actually like the tacos or guacamole here as even chains like Rubio's have better street tacos(they aren't too shabby actually).\\n\\nService: 5/5 they were nice and prompt\\nAmbiance: definitely take out unless you like picnics\\nparking: pretty terrible if I recall\\nfood: 0/5 worst tacos I have ever had, guacamole also. I don't mean to be jaded but it was a terrible experience\\n\\nThere isn't many options so I didn't try too much here on the visit with my girlfriend and kid but I won't be going back and still don't know how in the world this could ever be ranked in any food critics reviews.\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# false positive: model is reacting to the words \"good\", \"impressive\", \"nice\"\n",
    "X_test[22525]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Cool historic building but the service at lunch today was mediocre at best and stay away from the Chicken Parmigiana unless you like fishy tasting chicken.  The best part of my experience was the bread and butter.  :('"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# false positive: Not enough data to work with\n",
    "X_test[192552]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179135    Just saw Mission Impossible (Ghost Protocol) a...\n",
       "221005    I've been here many times purchasing and/or re...\n",
       "104737    My recent trip to Snowbowl had a bus breakdown...\n",
       "29135     My former brother-in-law used to do all of our...\n",
       "103490    after reading the reviews this morning I decid...\n",
       "211439    Wowoweewow.\\n\\nI've never been so fascinated a...\n",
       "64687     Whoa, a woman lost a $70000 engagement ring in...\n",
       "9297      Fast service, the woman who did my hair was gr...\n",
       "155531    crazy quick!!!! I got there around 10:20 and w...\n",
       "119562    HELLS YEAH! I'll never eat people again! this ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# False negatives\n",
    "X_test[y_test>y_pred_class].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Whoa, a woman lost a $70000 engagement ring in the toilet at this place!\\n\\n\"A Phoenix plumber became a hero after retrieving a $70,000 ring that had been flushed down the toilet of a Phoenix restaurant.\\n\\n\"We just did what we do,\" said Mike Roberts, general manager of Mr. Rooter, a plumbing company. Roberts said he spent about eight hours fishing down the toilet with a fiber optic cable on Jan. 14.\\n\\nThe woman, Allison Berry, from California had gone to the restroom after eating at Phoenix\\'s Black Bear Diner, 2410 West Bell Road when the accident happened. Her 7-carat diamond ring slipped off her finger and into the toilet as she was pulling up her pants, she reportedly told a waitress.\"\\n\\nRead more: http://www.azcentral.com/community/phoenix/articles/2009/01/23/20090123toilet0124.html'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# false negative: Model is reacting on the word 'poor and sad'\n",
    "X_test[64687]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8 (Challenge)\n",
    "Calculate which 10 tokens are the most predictive of 5-star reviews, and which 10 tokens are the most predictive of 1-star reviews.\n",
    "Hint: Naive Bayes automatically counts the number of times each token appears in each class, as well as the number of observations in each class. You can access these counts via the feature_count_ and class_count_ attributes of the Naive Bayes model object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68775"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store the vocabularies\n",
    "X_train_tokens = vect.get_feature_names()\n",
    "len(X_train_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2L, 68775L)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the features by the nb\n",
    "nb.feature_count_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "one_star_token_count = nb.feature_count_[0,:]\n",
    "five_star_token_count = nb.feature_count_[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a DataFrame of tokens with their separate one-star and five-star counts\n",
    "dftoken = pd.DataFrame({'token':X_train_tokens,'one_star':one_star_token_count,'five_star':five_star_token_count}).set_index('token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>five_star</th>\n",
       "      <th>one_star</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00</th>\n",
       "      <td>783.0</td>\n",
       "      <td>559.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>143.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0005</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000s</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000sf</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       five_star  one_star\n",
       "token                     \n",
       "00         783.0     559.0\n",
       "000        143.0      88.0\n",
       "0005         0.0       1.0\n",
       "000s         1.0       0.0\n",
       "000sf        1.0       0.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftoken.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add token by one to avoid dividing by 0\n",
    "dftoken['one_star'] = dftoken['one_star'] +1\n",
    "dftoken['five_star'] = dftoken['five_star'] +1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 13127.,  57154.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.class_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dftoken['one_star'] = dftoken['one_star']/nb.class_count_[0]\n",
    "dftoken['five_star'] = dftoken['five_star']/nb.class_count_[0]\n",
    "dftoken['five_star_ratio'] = dftoken['five_star']/dftoken['one_star']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>five_star</th>\n",
       "      <th>one_star</th>\n",
       "      <th>five_star_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>unassuming</th>\n",
       "      <td>0.009294</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deliciousness</th>\n",
       "      <td>0.016683</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>109.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>downside</th>\n",
       "      <td>0.015845</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scrumptious</th>\n",
       "      <td>0.015388</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>faves</th>\n",
       "      <td>0.007237</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               five_star  one_star  five_star_ratio\n",
       "token                                              \n",
       "unassuming      0.009294  0.000076            122.0\n",
       "deliciousness   0.016683  0.000152            109.5\n",
       "downside        0.015845  0.000152            104.0\n",
       "scrumptious     0.015388  0.000152            101.0\n",
       "faves           0.007237  0.000076             95.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftoken.sort_values('five_star_ratio',ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 9 (Challenge)\n",
    "Up to this point, we have framed this as a binary classification problem by only considering the 5-star and 1-star reviews. Now, let's repeat the model building process using all reviews, which makes this a 5-class classification problem.\n",
    "Here are the steps:\n",
    "Define X and y using the original DataFrame. (y should contain 5 different classes.)\n",
    "Split X and y into training and testing sets.\n",
    "Create document-term matrices using CountVectorizer.\n",
    "Calculate the testing accuracy of a Multinomial Naive Bayes model.\n",
    "Compare the testing accuracy with the null accuracy, and comment on the results.\n",
    "Print the confusion matrix, and comment on the results. (This Stack Overflow answer explains how to read a multi-class confusion matrix.)\n",
    "Print the classification report, and comment on the results. If you are unfamiliar with the terminology it uses, research the terms, and then try to figure out how to calculate these metrics manually from the confusion matrix!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=df.text\n",
    "y= df.stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split with train test split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train the vector\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()\n",
    "\n",
    "X_train_dtm = vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test_dtm = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use naive bayes model\n",
    "nb.fit(X_train_dtm,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make class prediction\n",
    "y_pred_class = nb.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54112079614454478"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the accuracy\n",
    "metrics.accuracy_score(y_test,y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2427,  1078,   427,   212,   169],\n",
       "       [  966,  1579,  1828,   706,   230],\n",
       "       [  488,   758,  3268,  3625,   669],\n",
       "       [  486,   322,  1800, 12186,  5239],\n",
       "       [  720,   123,   315,  6214, 11642]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the confusion matrix\n",
    "metrics.confusion_matrix(y_test,y_pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix comments:\n",
    "Nearly all 4-star and 5-star reviews are classified as 4 or 5 stars, but they are hard for the model to distinguish between.\n",
    "1-star, 2-star, and 3-star reviews are most commonly classified as 4 stars, probably because it's the predominant class in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.48      0.56      0.52      4313\n",
      "          2       0.41      0.30      0.34      5309\n",
      "          3       0.43      0.37      0.40      8808\n",
      "          4       0.53      0.61      0.57     20033\n",
      "          5       0.65      0.61      0.63     19014\n",
      "\n",
      "avg / total       0.54      0.54      0.54     57477\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report\n",
    "print(metrics.classification_report(y_test,y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precision** answers the question: \"When a given class is predicted, how often are those predictions correct?\" To calculate the precision for class 1, for example, you divide 55 by the sum of the first column of the confusion matrix.\n",
    "\n",
    "**Recall** answers the question: \"When a given class is the true class, how often is that class predicted?\" To calculate the recall for class 1, for example, you divide 55 by the sum of the first row of the confusion matrix.\n",
    "\n",
    "**F1** score is a weighted average of precision and recall.\n",
    "\n",
    "**Support answers the question**: \"How many observations exist for which a given class is the true class?\" To calculate the support for class 1, for example, you sum the first row of the confusion matrix.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification report comments:\n",
    "1. Class 2 has low recall, meaning that the model has a hard time detecting the 1-star reviews, but decent precision, meaning that when the model predicts a review is 2-star, it's likely to be correct.\n",
    "2. Class 4 and 5 has high recall and precision, probably because 4-star and 5-star reviews have polarized language, and because the model has a lot of observations to learn from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the entire file of json\n",
    "with open('..\\..\\HeavyDataset\\Yelp Business Rating Prediction\\yelp_test_set\\yelp_test_set_review.json', 'rb') as file:\n",
    "    data = file.readlines()\n",
    "\n",
    "# Joining all data into a lump JSON String\n",
    "data_json_str = \"[\" + ','.join(data) + \"]\"\n",
    "\n",
    "# now, load it into pandas\n",
    "dftest = pd.read_json(data_json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22956, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AuMz7XGkjLcIUurp_AD51w</td>\n",
       "      <td>review</td>\n",
       "      <td>2WkM3pYfx7bt46tv7u4hHA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8i5hB_dmf33NVbWE5SwoMQ</td>\n",
       "      <td>review</td>\n",
       "      <td>eHWbF0k5QOBLgQXhGdeHmg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nvaAUTTl7oqiJDhuimNG6A</td>\n",
       "      <td>review</td>\n",
       "      <td>HrjjHfDGTafXyKpQKNrYHg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QwaoxP5Mgm3PJuZo_4bFsw</td>\n",
       "      <td>review</td>\n",
       "      <td>DrWLhrK8WMZf7Jb-Oqc7ww</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0lEp4vISRmOXa8Xz2pWhbw</td>\n",
       "      <td>review</td>\n",
       "      <td>jDCONTPR6nyc3J7iimwzkQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id    type                 user_id\n",
       "0  AuMz7XGkjLcIUurp_AD51w  review  2WkM3pYfx7bt46tv7u4hHA\n",
       "1  8i5hB_dmf33NVbWE5SwoMQ  review  eHWbF0k5QOBLgQXhGdeHmg\n",
       "2  nvaAUTTl7oqiJDhuimNG6A  review  HrjjHfDGTafXyKpQKNrYHg\n",
       "3  QwaoxP5Mgm3PJuZo_4bFsw  review  DrWLhrK8WMZf7Jb-Oqc7ww\n",
       "4  0lEp4vISRmOXa8Xz2pWhbw  review  jDCONTPR6nyc3J7iimwzkQ"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dftest.shape)\n",
    "dftest.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
