{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Value Investing Program\n",
    "# Introduction\n",
    "\n",
    "Inspired by Sean Seah Book -- Gone Fishing with Warren Buffetthttp://www.aceprofitsacademy.com/wp-content/uploads/2016/09/Gone-Fishing-with-Buffett.pdf\n",
    "\n",
    "In here we are going to try to scrape financial data:\n",
    "Input: List of the companies\n",
    "\n",
    "Web scraping: \n",
    "* Find the shareprice by year and the following metrics:\n",
    "    * EPS\n",
    "    * ROE\n",
    "    * ROA\n",
    "    * Long term debt\n",
    "    * Total Income\n",
    "    * Debt to Equity\n",
    "    * Interest Coverage Ratio\n",
    "\n",
    "Methods:\n",
    "* Given list of the companies, find out the feasibility to invest\n",
    "    * Been in market minimal 10 years\n",
    "    * Have the track records (EPS per year)\n",
    "    * Have efficiency (ROE > 15%) -- Net income / shareholder equity\n",
    "    * Determine manipulation (ROA > 7%) -- Net income / Total Asset\n",
    "    * Have small long term debt (Long term debt <5* total income)\n",
    "    * Low Debt to Equity\n",
    "    * Ability to pay interest: (Interest Coverage Ratio >3) -- EBIT / Interest expenses\n",
    "\n",
    "Outputs:\n",
    "* Ranking of each company in terms of return rate given the value investing methodology\n",
    "    * Find EPS Annual Compounded Growth Rate\n",
    "    * Estimate EPS 10 years from now\n",
    "    * Estimate stock price 10 years from now (Stock Price EPS * Average PE)\n",
    "    * Determine target by price today based on returns(discount rate 15%/20%)\n",
    "    * Add margin of safety (Safety net 15%)\n",
    "\n",
    "Additional:\n",
    "* Qualitative Assessment of the companies\n",
    "    * Advantages in business (product differentiation, branding, low price producer, high switching cost, legal barriers to entry)\n",
    "    * Ability of foolhardy management (even a fool can run)\n",
    "    * Avoid price competitive business    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiating all parameters/addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "urlwikisp500 = 'http://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "urlmarketwatch = 'http://www.marketwatch.com/investing/stock/'\n",
    "\n",
    "locblacklist = 'C:/Users/vintatan/Desktop/Investment/blacklist.csv'\n",
    "\n",
    "locsp500anddata = \"C:/Users/vintatan/Desktop/Investment/SP500andData.csv\"\n",
    "picklefinancialreport= 'C:/Users/vintatan/Desktop/Investment/financialreport.pickle'\n",
    "locstocksanalysis = 'C:/Users/vintatan/Desktop/Investment/stocksanalysis.csv'\n",
    "\n",
    "locrussellanddata = \"C:/Users/vintatan/Desktop/Investment/RussellandData.csv\"\n",
    "picklerussellfinancialreport= 'C:/Users/vintatan/Desktop/Investment/russellfinancialreport.pickle'\n",
    "locrussellstocksanalysis = 'C:/Users/vintatan/Desktop/Investment/russellstocksanalysis.csv'\n",
    "\n",
    "analyse_sp_or_russell = 'russell'\n",
    "\n",
    "if (analyse_sp_or_russell=='russell'):\n",
    "    picklefinancialreport=picklerussellfinancialreport\n",
    "    locstocksanalysis=locrussellstocksanalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read blacklist\n",
    "\n",
    "# Blacklist list to remove from calculation\n",
    "import csv\n",
    "blacklist =[]\n",
    "with open(locblacklist) as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        blacklist.append(row)\n",
    "blacklist = blacklist[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scraping Russell Data Using Beautiful Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reading russel stocks plans and getting the 2000 stocks\n",
    "dfrussel = pd.read_html('http://www.kibot.com/Historical_Data/Russell_3000_Historical_Intraday_Data.aspx', flavor='bs4')[1];\n",
    "dfrussel.columns = dfrussel.iloc[0]\n",
    "dfrussel = dfrussel.reindex(dfrussel.index.drop(0))\n",
    "dfrussel = dfrussel.drop('#',axis=1)\n",
    "dfrussel.set_index('Symbol',inplace=True)\n",
    "dfrussel.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'A', u'AA', u'AAN', u'AAON', u'AAP', u'AAPL', u'AAT', u'AAWW', u'ABAX',\n",
       "       u'ABBV',\n",
       "       ...\n",
       "       u'ZBRA', u'ZEUS', u'ZGNX', u'ZION', u'ZIOP', u'ZIXI', u'ZN', u'ZNGA',\n",
       "       u'ZTS', u'ZUMZ'],\n",
       "      dtype='object', name=u'Symbol', length=2528)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfrussel.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickersrussel = dfrussel.index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfrussel['labels'] = dfrussel[['Description','Industry', 'Sector']].apply(lambda x: ' '.join(x), axis=1)\n",
    "dfrussel.to_csv(locrussellanddata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Wikipedia SP500 Data Using Beautiful Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bs4 as bs\n",
    "import pickle\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# This will keep tickers + gics industries & sub industries\n",
    "## Time\n",
    "# 40 seconds for 10 tickers\n",
    "# 3 minutes for 50 tickers\n",
    "\n",
    "def save_sp500_stocks_info():\n",
    "    resp = requests.get(urlwikisp500)\n",
    "    soup = bs.BeautifulSoup(resp.text, 'lxml')\n",
    "    table = soup.find('table', {'class': 'wikitable sortable'})\n",
    "    stocks_info=[]\n",
    "    tickers = []\n",
    "    securities = []\n",
    "    gics_industries = []\n",
    "    gics_sub_industries = []\n",
    "    for row in table.findAll('tr')[1:]:\n",
    "        ticker = row.findAll('td')[0].text\n",
    "        security = row.findAll('td')[1].text\n",
    "        gics_industry = row.findAll('td')[3].text\n",
    "        gics_sub_industry = row.findAll('td')[4].text\n",
    "\n",
    "        tickers.append(ticker.lower())\n",
    "        securities.append(security)\n",
    "        gics_industries.append(gics_industry.lower())\n",
    "        gics_sub_industries.append(gics_sub_industry.lower())\n",
    "    \n",
    "    stocks_info.append(tickers)\n",
    "    stocks_info.append(securities)\n",
    "    stocks_info.append(gics_industries)\n",
    "    stocks_info.append(gics_sub_industries)\n",
    "    return stocks_info\n",
    "\n",
    "stocks_info = save_sp500_stocks_info()\n",
    "stocks_info_df = pd.DataFrame(stocks_info).T\n",
    "stocks_info_df.columns=['tickers','security','gics_industry','gics_sub_industry']\n",
    "stocks_info_df.set_index('tickers',inplace=True)\n",
    "\n",
    "# Extract just the tickers list\n",
    "tickers= stocks_info[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stocks_info_df['labels'] = stocks_info_df[['security', 'gics_industry','gics_sub_industry']].apply(lambda x: ' '.join(x), axis=1)\n",
    "stocks_info_df.to_csv(locsp500anddata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a list of dict based on tickers and labels\n",
    "dictlist = []\n",
    "for index, row in stocks_info_df.iterrows():\n",
    "    dictlist.append({'value':index, 'label':row['labels']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging Russell and SP500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers=[]\n",
    "if(analyse_sp_or_russell =='russell'):\n",
    "    tickers= dfrussel.index\n",
    "else:\n",
    "    tickers= stocks_info[0]    \n",
    "\n",
    "    \n",
    "tickers=[x for x in tickers if x not in blacklist]\n",
    "tickersshort = tickers[:10]\n",
    "tickersmedium = tickers[:50]\n",
    "tickersmediumlarge = tickers[:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Getting lists of current stocks prices and give limitations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas_datareader.data as web\n",
    "\n",
    "days_per_year = 365.24\n",
    "start = datetime.datetime.now()-datetime.timedelta(days=2)\n",
    "end = datetime.datetime.now()\n",
    "\n",
    "def cheapstockspriceunderprice(price = 50, asc = True):\n",
    "    dfcomp = web.DataReader(tickers,'google',\n",
    "                                   start=start, \n",
    "                                   end=end)['Close'].T\n",
    "\n",
    "    dfcomp.columns =['stocksprice']\n",
    "    dfcompfilters = dfcomp[dfcomp.stocksprice<price]\n",
    "    dfcompsorted = dfcompfilters.sort_values('stocksprice',ascending=asc)\n",
    "    return dfcompsorted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vintatan\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\pandas_datareader\\base.py:201: SymbolWarning: Failed to read symbol: u'A', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "C:\\Users\\vintatan\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\pandas_datareader\\base.py:201: SymbolWarning: Failed to read symbol: u'AA', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "C:\\Users\\vintatan\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\pandas_datareader\\base.py:201: SymbolWarning: Failed to read symbol: u'AAN', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "C:\\Users\\vintatan\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\pandas_datareader\\base.py:201: SymbolWarning: Failed to read symbol: u'AAON', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "C:\\Users\\vintatan\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\pandas_datareader\\base.py:201: SymbolWarning: Failed to read symbol: u'AAP', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "C:\\Users\\vintatan\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\pandas_datareader\\base.py:201: SymbolWarning: Failed to read symbol: u'AAPL', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "C:\\Users\\vintatan\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\pandas_datareader\\base.py:201: SymbolWarning: Failed to read symbol: u'AAT', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "C:\\Users\\vintatan\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\pandas_datareader\\base.py:201: SymbolWarning: Failed to read symbol: u'AAWW', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "C:\\Users\\vintatan\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\pandas_datareader\\base.py:201: SymbolWarning: Failed to read symbol: u'ABAX', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "C:\\Users\\vintatan\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\pandas_datareader\\base.py:201: SymbolWarning: Failed to read symbol: u'ABBV', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "C:\\Users\\vintatan\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\pandas_datareader\\base.py:201: SymbolWarning: Failed to read symbol: u'ABC', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "C:\\Users\\vintatan\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\pandas_datareader\\base.py:201: SymbolWarning: Failed to read symbol: u'ABCB', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "C:\\Users\\vintatan\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\pandas_datareader\\base.py:201: SymbolWarning: Failed to read symbol: u'ABCD', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "C:\\Users\\vintatan\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\pandas_datareader\\base.py:201: SymbolWarning: Failed to read symbol: u'ABCO', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "C:\\Users\\vintatan\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\pandas_datareader\\base.py:201: SymbolWarning: Failed to read symbol: u'ABG', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "C:\\Users\\vintatan\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\pandas_datareader\\base.py:201: SymbolWarning: Failed to read symbol: u'ABM', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "C:\\Users\\vintatan\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\pandas_datareader\\base.py:201: SymbolWarning: Failed to read symbol: u'ABMD', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "C:\\Users\\vintatan\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\pandas_datareader\\base.py:201: SymbolWarning: Failed to read symbol: u'ABR', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "C:\\Users\\vintatan\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\pandas_datareader\\base.py:201: SymbolWarning: Failed to read symbol: u'ABT', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "C:\\Users\\vintatan\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\pandas_datareader\\base.py:201: SymbolWarning: Failed to read symbol: u'ACAD', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "C:\\Users\\vintatan\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\pandas_datareader\\base.py:201: SymbolWarning: Failed to read symbol: u'ACC', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "C:\\Users\\vintatan\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\pandas_datareader\\base.py:201: SymbolWarning: Failed to read symbol: u'ACCO', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "C:\\Users\\vintatan\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\pandas_datareader\\base.py:201: SymbolWarning: Failed to read symbol: u'ACET', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "C:\\Users\\vintatan\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\pandas_datareader\\base.py:201: SymbolWarning: Failed to read symbol: u'ACFN', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "C:\\Users\\vintatan\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\pandas_datareader\\base.py:201: SymbolWarning: Failed to read symbol: u'ACGL', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "C:\\Users\\vintatan\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\pandas_datareader\\base.py:201: SymbolWarning: Failed to read symbol: u'ACHC', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "C:\\Users\\vintatan\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\pandas_datareader\\base.py:201: SymbolWarning: Failed to read symbol: u'ACHN', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "C:\\Users\\vintatan\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\pandas_datareader\\base.py:201: SymbolWarning: Failed to read symbol: u'ACIW', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "C:\\Users\\vintatan\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\pandas_datareader\\base.py:201: SymbolWarning: Failed to read symbol: u'ACLS', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "C:\\Users\\vintatan\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\pandas_datareader\\base.py:201: SymbolWarning: Failed to read symbol: u'ACM', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "C:\\Users\\vintatan\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\pandas_datareader\\base.py:201: SymbolWarning: Failed to read symbol: u'ACN', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "C:\\Users\\vintatan\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\pandas_datareader\\base.py:201: SymbolWarning: Failed to read symbol: u'ACOR', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "C:\\Users\\vintatan\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\pandas_datareader\\base.py:201: SymbolWarning: Failed to read symbol: u'ACRE', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "C:\\Users\\vintatan\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\pandas_datareader\\base.py:201: SymbolWarning: Failed to read symbol: u'ACRX', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "C:\\Users\\vintatan\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\pandas_datareader\\base.py:201: SymbolWarning: Failed to read symbol: u'ACTG', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "C:\\Users\\vintatan\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\pandas_datareader\\base.py:201: SymbolWarning: Failed to read symbol: u'ACUR', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "C:\\Users\\vintatan\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\pandas_datareader\\base.py:201: SymbolWarning: Failed to read symbol: u'ACXM', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "C:\\Users\\vintatan\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\pandas_datareader\\base.py:201: SymbolWarning: Failed to read symbol: u'ADBE', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "C:\\Users\\vintatan\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\pandas_datareader\\base.py:201: SymbolWarning: Failed to read symbol: u'ADC', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vintatan\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\pandas_datareader\\base.py:201: SymbolWarning: Failed to read symbol: u'ADES', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "C:\\Users\\vintatan\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\pandas_datareader\\base.py:201: SymbolWarning: Failed to read symbol: u'ADI', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "C:\\Users\\vintatan\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\pandas_datareader\\base.py:201: SymbolWarning: Failed to read symbol: u'ADM', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "C:\\Users\\vintatan\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\pandas_datareader\\base.py:201: SymbolWarning: Failed to read symbol: u'ADP', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "C:\\Users\\vintatan\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\pandas_datareader\\base.py:201: SymbolWarning: Failed to read symbol: u'ADS', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n"
     ]
    }
   ],
   "source": [
    "dfcompsorted = cheapstockspriceunderprice()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping marketwatch Data Using Beautiful Soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting all the values to numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format(list):\n",
    "    newlist=[]\n",
    "    posornegnumber = 1\n",
    "    for text in list:\n",
    "        if text.endswith(')'):\n",
    "            text = text[1:-1] # remove the parentheses\n",
    "            posornegnumber = -1\n",
    "            \n",
    "        if text.endswith('%'):\n",
    "#             Then please make it into comma float\n",
    "            endtext = float(text[:-1])/100.0 * posornegnumber \n",
    "        elif text.endswith('B'):\n",
    "#             Then please times 1000000000\n",
    "#             Change it into integer\n",
    "            endtext = int(float(text[:-1])*1000000000)* posornegnumber \n",
    "        elif text.endswith('M'):\n",
    "#             Then please times 1000000\n",
    "#             Change it into integer\n",
    "            endtext = int(float(text[:-1])*1000000)* posornegnumber \n",
    "        elif ',' in text:\n",
    "#             Then please remove the ,\n",
    "#             Then change it into int\n",
    "            endtext = int(float(text.replace(\",\",\"\")))* posornegnumber \n",
    "\n",
    "        elif text.endswith('-'):\n",
    "#             Insert 0\n",
    "            endtext = 0\n",
    "        else:\n",
    "#             change to float\n",
    "            endtext = float(text)* posornegnumber \n",
    "        newlist.append(endtext)\n",
    "    return newlist   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Financial Reporting (Balance Sheet and Income Statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "from urllib import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "dflist = []\n",
    "tickersnotfound =[] \n",
    "counter = 0\n",
    "\n",
    "for ticker in dfcompsorted.index: \n",
    "    try:\n",
    "        urlfinancials = urlmarketwatch+ticker+'/financials'\n",
    "        urlbalancesheet = urlmarketwatch+ticker+'/financials/balance-sheet'\n",
    "\n",
    "        text_soup_financials = BeautifulSoup(urlopen(urlfinancials).read()) #read in\n",
    "        text_soup_balancesheet = BeautifulSoup(urlopen(urlbalancesheet).read()) #read in\n",
    "\n",
    "        # Income statement\n",
    "        titlesfinancials = text_soup_financials.findAll('td', {'class': 'rowTitle'})\n",
    "        epslist=[]\n",
    "        netincomelist = []\n",
    "        longtermdebtlist = [] \n",
    "        interestexpenselist = []\n",
    "        ebitdalist= []\n",
    "\n",
    "        for title in titlesfinancials:\n",
    "            if 'EPS (Basic)' in title.text:\n",
    "                epslist.append ([td.text for td in title.findNextSiblings(attrs={'class': 'valueCell'}) if td.text])\n",
    "            if 'Net Income' in title.text:\n",
    "                netincomelist.append ([td.text for td in title.findNextSiblings(attrs={'class': 'valueCell'}) if td.text])\n",
    "            if 'Interest Expense' in title.text:\n",
    "                interestexpenselist.append ([td.text for td in title.findNextSiblings(attrs={'class': 'valueCell'}) if td.text])\n",
    "            if 'EBITDA' in title.text:\n",
    "                ebitdalist.append ([td.text for td in title.findNextSiblings(attrs={'class': 'valueCell'}) if td.text])\n",
    "\n",
    "\n",
    "        # Balance sheet\n",
    "        titlesbalancesheet = text_soup_balancesheet.findAll('td', {'class': 'rowTitle'})\n",
    "        equitylist=[]\n",
    "        for title in titlesbalancesheet:\n",
    "            if 'Total Shareholders\\' Equity' in title.text:\n",
    "                equitylist.append( [td.text for td in title.findNextSiblings(attrs={'class': 'valueCell'}) if td.text])\n",
    "            if 'Long-Term Debt' in title.text:\n",
    "                longtermdebtlist.append( [td.text for td in title.findNextSiblings(attrs={'class': 'valueCell'}) if td.text])\n",
    "\n",
    "        # Variables        \n",
    "        eps = epslist[0]\n",
    "        epsgrowth = epslist[1]\n",
    "        netincome = netincomelist[0]\n",
    "        shareholderequity = equitylist[0]\n",
    "        roa = equitylist[1]\n",
    "\n",
    "        longtermdebt = longtermdebtlist[0]\n",
    "        interestexpense = interestexpenselist[0]\n",
    "        ebitda = ebitdalist[0]\n",
    "        # Don't forget to add in roe, interest coverage ratio\n",
    "\n",
    "        ## Make it into Dataframes\n",
    "        df= pd.DataFrame({'eps': eps,'epsgrowth': epsgrowth,'netincome': netincome,'shareholderequity': shareholderequity,'roa': \n",
    "                      roa,'longtermdebt': longtermdebt,'interestexpense': interestexpense,'ebitda': ebitda},index=[2012,2013,2014,2015,2016])\n",
    "\n",
    "        # Format all the number in dataframe\n",
    "        dfformatted = df.apply(format)\n",
    "\n",
    "        # Adding roe, interest coverage ratio\n",
    "        dfformatted['roe'] = dfformatted.netincome/dfformatted.shareholderequity\n",
    "        dfformatted['interestcoverageratio'] = dfformatted.ebitda/dfformatted.interestexpense\n",
    "\n",
    "    #     Insert ticker and df\n",
    "        dflist.append((ticker,dfformatted))\n",
    "        \n",
    "        counter+=1\n",
    "        print(ticker, ' has been processed')\n",
    "    except:\n",
    "        tickersnotfound.append(ticker)\n",
    "        print(ticker,' ticker is not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Inputting the failed to the not to be processed subsequently.\n",
    "stickersnotfound = ','+','.join(map(str, tickersnotfound)) \n",
    "with open(locblacklist,'ab') as f:\n",
    "        f.write(stickersnotfound )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dflist[0][1].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dflist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pickle for writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filehandler = open(locfinancialreportpickle, 'w') \n",
    "pickle.dump(dflist, filehandler) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pickle for Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filehandler = open(locfinancialreportpickle, 'r') \n",
    "dflist = pickle.load(filehandler) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining legibility\n",
    "Find whether this particular stocks is legitimate using this and filter accordingly\n",
    "    1. EPS increases over the year (consistent)\n",
    "    2. ROE > 0.15\n",
    "    3. ROA > 0.07 (also consider debt to equity cause Assets = liabilities + equity)\n",
    "    4. Long term debt < 5 * income\n",
    "    5. Interest Coverage Ratio > 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eligibilitycheck(df):\n",
    "    ticker,dfformatted = df\n",
    "    \n",
    "    legiblestock = True\n",
    "    reasonlist=[]\n",
    "\n",
    "    # EPS increases over the year (consistent)\n",
    "#     Counting 2 or more negative growth\n",
    "    countnegativegrowth =0\n",
    "    for growth in dfformatted.epsgrowth:\n",
    "        if growth<0:\n",
    "            countnegativegrowth+=1\n",
    "        if countnegativegrowth>=2:\n",
    "            legiblestock = False\n",
    "            reasonlist.append('there are 2 negative growth '+str(growth))\n",
    "            break\n",
    "    # ROE > 0.15\n",
    "    if dfformatted.roe.mean()<0.15:\n",
    "            legiblestock = False\n",
    "            reasonlist.append('roe mean is less than 0.13 '+ str(dfformatted.roe.mean()))\n",
    "    # ROA > 0.07 (also consider debt to equity cause Assets = liabilities + equity)\n",
    "    if dfformatted.roa.mean()<0.07:\n",
    "            legiblestock = False\n",
    "            reasonlist.append('roa mean is less than 0.07 ' + str(dfformatted.roa.mean()))\n",
    "    # Long term debt < 5 * income\n",
    "    if dfformatted.longtermdebt.tail(1).values[0]>5*dfformatted.netincome.tail(1).values[0]:\n",
    "            legiblestock = False\n",
    "            reasonlist.append('longtermdebt is 5 times the netincome ')\n",
    "    # Interest Coverage Ratio > 3\n",
    "    if dfformatted.interestcoverageratio.tail(1).values[0]<3:\n",
    "            legiblestock = False\n",
    "            reasonlist.append('Interestcoverageratio is less than 3 ')\n",
    "#     print ticker,legiblestock,reasonlist\n",
    "    return ticker,legiblestock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selectiondflist = []\n",
    "for df in dflist:\n",
    "    if eligibilitycheck(df)[1]:\n",
    "        selectiondflist.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dflist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(selectiondflist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What are the tickers of these?\n",
    "tickersselections = [x[0] for x in selectiondflist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickersselections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping for latest shareprice using selectiondflist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selecteddfcomp = dfcompsorted[dfcompsorted.index.isin(tickersselections)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using selectiondflist to calculate stocks price value\n",
    "\n",
    "Outputs:\n",
    "1. Ranking of each company in terms of return rate given the value investing methodology\n",
    "    a. Find EPS Annual Compounded Growth Rate\n",
    "    b. Estimate EPS 10 years from now\n",
    "    c. Estimate stock price 10 years from now (Stock Price EPS * Average PE)\n",
    "    d. Determine target by price today based on returns(discount rate 15%/20%)\n",
    "    e. Add margin of safety (Safety net 15%)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dfprice = pd.DataFrame(columns =['ticker','annualgrowthrate','lasteps','futureeps'])\n",
    "i=0\n",
    "for tuple in selectiondflist:\n",
    "    ticker, df = tuple\n",
    "    \n",
    "    # Find EPS Annual Compounded Growth Rate\n",
    "    annualgrowthrate =  df.epsgrowth.mean() #growth rate\n",
    "    \n",
    "    # Estimate stock price 10 years from now (Stock Price EPS * Average PE)\n",
    "    lasteps = df.eps.tail(1).values[0] #presentvalue\n",
    "    years  = 10 #period\n",
    "    \n",
    "    futureeps = abs(np.fv(annualgrowthrate,years,0,lasteps))\n",
    "        \n",
    "    dfprice.loc[i] = [ticker,annualgrowthrate,lasteps,futureeps]\n",
    "    i+=1\n",
    "    \n",
    "dfprice.set_index('ticker',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfprice['lastshareprice']=selecteddfcomp.stocksprice\n",
    "dfprice['peratio'] = dfprice['lastshareprice']/dfprice['lasteps']\n",
    "dfprice['futureshareprice'] = dfprice['futureeps']*dfprice['peratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "discountrate = 0.2\n",
    "margin = 0.15\n",
    "\n",
    "dfprice['discshareprice'] = abs(np.pv(discountrate,years,0,fv=dfprice['futureshareprice']))\n",
    "dfprice['marginalizedprice'] = dfprice['discshareprice']*(1-0.15) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfprice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mergestocksdf = pd.merge(stocks_info_df, dfprice, how='inner', left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mergestocksdf['Buy'] = mergestocksdf.lastshareprice<=mergestocksdf.marginalizedprice\n",
    "mergestocksdf['newsurl'] = 'http://www.cnbc.com/quotes/?symbol='+mergestocksdf.index\n",
    "mergestocksdf['dividendhistoryurl'] = 'http://www.nasdaq.com/symbol/'+mergestocksdf.index+'/dividend-history'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergestocksdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mergestocksdf.to_csv(locstocksanalysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergestocksdf[mergestocksdf.Buy==True].sort_values('marginalizedprice',ascending=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
